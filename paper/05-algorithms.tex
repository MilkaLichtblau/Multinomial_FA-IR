\section{Algorithm}\label{sec:algorithms}
We present the multinomial \algoFAIR algorithm (\S\ref{subsec:algorithm-description}) and prove it is correct (\S\ref{subsec:algorithm-correctness}).

\subsection{Algorithm Description}\label{subsec:algorithm-description}
\note{Done}
Multinomial \algoFAIR, presented in Algorithm~\ref{alg:fair}, solves the {\sc Fair Top-$k$ Ranking} problem for multinomial protected groups and intersectional group settings.
%
As input, multinomial \algoFAIR takes 
the expected size $k$ of the ranking to be returned,
the qualifications $q_c$, 
indicator variables $g_c$ indicating if candidate $c$ is protected,
the vector of minimum target proportions $p_G$, and
the adjusted significance level $\alphaadj$.

First, the algorithm uses $q_c$ to create priority queues with up to $k$ candidates each: $P_0$ for the non-protected candidates and $P_g$ for the protected candidates of group $g$.
%
Next (line \ref{alg:fair:mtree}), the algorithm derives a ranked group fairness tree (mTree) similar to Figure~\ref{fig:mtree-asymmetric-adjusted}, i.e., for each position it computes the minimum number of protected candidates per group, given $p_G$, $k$ and $\alphaadj$.
%
Then, multinomial \algoFAIR greedily constructs a ranking subject to candidate qualifications, and minimum protected elements required.
%
Note that the right choice of a tree node on level $i$ depends on the path chosen along the tree and therefore on its concrete parent at level $i-1$. 
%
In case \texttt{mtree} branches into different possibilities to satisfy ranked group fairness (as an example see Fig.~\ref{fig:mtree-asymmetric-adjusted} for $k=4$), the algorithm chooses the branch that has a higher value for $F$, meaning it chooses the branch that has a higher probability.
%
If two branches are equally likely, which happens for $p_1 = p_2 = \ldots = p_{|G|}$, then one of them is chosen at random.
%
Given this the algorithm has to find the correct child $m_{G,i}$ for a given parent from the previous level (Line~\ref{alg:fair:childNode}).
%
If the node demands a protected candidate from group $g$ at the current position $i$, the algorithm appends the best candidate from $P_g$ to the ranking (Lines \ref{alg:fair:pstart}-\ref{alg:fair:pend}); otherwise, it appends the best candidate from $P_0 \cup P_1 \cup \ldots \cup P_{|G|}$ (Lines \ref{alg:fair:anystart}-\ref{alg:fair:anyend}).
%

\begin{algorithm}[h]
	%\caption{Algorithm \algoFAIR, finding a ranking that maximizes utility subject to in-group monotonicity and ranked group fairness constraints.}
	\caption{Algorithm \algoFAIR finds a ranking that maximizes utility subject to in-group monotonicity and ranked group fairness constraints. Checks for special cases (e.g., insufficient candidates of a class) are not included for clarity.}
	\label{alg:fair}  % But whenever possible refer to this algo. by name not number
	\small
	\AlgInput{$k \in [n]$, the size of the list to return; $\forall~c \in [n]$: $q_c$, the qualifications for candidate $c$, and $g_c$ an indicator that is $>0$ iff candidate $c$ is protected; $p_G$ with $\forall p \in p_G \in ]0,1[$, the vector of minimum proportions for each group of protected elements; $\alphaadj \in ]0,1[$, the adjusted significance for each fair representation test.}
	\AlgOutput{$\tau$ satisfying the group fairness condition with parameters $p, \sigma$, and maximizing utility.}
	%\AlgComment{compute min. protected candidates per position}
	$P_0, P_1, \ldots P_{|G|} \leftarrow$ empty priority queues with bounded capacity $k$\\
	\For{$c \leftarrow 1$ \KwTo $n$}{
		insert $c$ with value $q_c$ in priority queue $P_{g_c}$ \\
	}

	$\texttt{mtree}(i) \leftarrow \texttt{\algoComputeMTree}(k, p_G, \alphaadj)$  \label{alg:fair:mtree}\\
		
	%\AlgComment{create fair ranking}
	$(t_0, t_1, \ldots, t_{|G|}) \leftarrow (0, \ldots, 0)$ \\
	$i \leftarrow 0 $ \\
	\While{$i < k$}{
		\texttt{noCandidateAdded = True} \\
		\AlgComment{get next node in tree path}
		$m_{G, i} = [m_1(i), \ldots, m_{|G|}(i)] \leftarrow \texttt{findNextNode(mtree, i)}$ \label{alg:fair:childNode}\\
		\AlgComment{find which group needs a new candidate}
		\For{\texttt{g = 1; g} $\leq$ \texttt{|G|; g++}}{

			\If{$t_g < m_g(i)$}{\label{alg:fair:pstart}
				\AlgComment{add a protected candidate}
				$t_g \leftarrow t_g + 1$ \\ 
				$\tau[i] \leftarrow \operatorname{pop}(P_g)$ \\  
				\texttt{noCandidateAdded = False}
			}\label{alg:fair:pend}
		}
		\If{\texttt{noCandidateAdded}}{ \label{alg:fair:anystart}
			\AlgComment{no protected candidate needed: add the best available}
			$P_g \leftarrow$ \texttt{findBestCandidateQueue()} \\
			$\tau[i] \leftarrow \operatorname{pop}(P_g)$\\
			$t_g \leftarrow t_g + 1$ 
		}\label{alg:fair:anyend}
		
	}
	\Return{$\tau$}
\end{algorithm}
\vspace{-3mm}

\subsection{Algorithm Complexity}
\todo{Not done yet}

\begin{table}[]
\caption{Space and time complexity for all algorithms.
		\label{tbl:space_time}}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Algorithm} & \textbf{Time Complexity} & \textbf{Space Complexity} \\ \hline
inverseBinomialCDF & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoMtable & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoRecursive & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoBinomBinary & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
multinomialCDF & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoImcdf & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoComputeMTree & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoMultBinary & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoReg & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\algoFAIR & $\mathcal{O}(n\log{}n)$ & $\mathcal{O}(n\log{}n)$ \\ \hline
\end{tabular}
\end{table}

\algoFAIR has running time $O(n + k \log k)$; which includes building the $O(k)$ size priority queues from $n$ items and processing them to obtain the final ranking, where we assume $k < O(n/\log n)$. 
\meike{Was soll denn $k < O(n/\log n)$ heiÃŸen? Warum ist die size der priority queues O(k) und nicht k?}
%
If we already have ranked lists for all groups of elements, \algoFAIR can avoid the first step and obtain the top-$k$ in $O(k \log k)$ time.
%
Our method is applicable as long as there is at least one protected group and there are enough candidates in each protected group; if there are $k$ from each group, the algorithm is guaranteed to succeed, otherwise the ``head'' of the ranking will satisfy the ranked group fairness constraint, but the ``tail'' of the ranking may not.

\subsection{Algorithm Optimizations}
\note{Done}
Because the computation of an adjusted mTree is expensive (Table~\ref{tbl:space_time}), our implementation persists already computed mTrees and their components to never do the same computation twice. 
%
Depending on the structure of $p_G$, different levels of optimization are applicable.

We note however that an mTree has to be computed only once for a particular combination of $k, p_G, \alpha$ and that \algoFAIR has a complexity of $O(k log k)$.
%
We provide the already pre-computed mTrees and MCDF caches for our experiments and the intermediate steps not only for reproducibility but for use in practice too.

\subsubsection{MCDF Cache}\label{subsubsec:mcdf-cache}
Table~\ref{tbl:space_time} shows that the highest computational cost arises from computing the multinomial cumulative distribution function $F$. 
%
In the worst case Algorithm~\ref{alg:imcdf} computes it $|G|+1$ times for each group $g$ in $m_g(i)$ and each position $i\leq k$.
%
However, the same calculation may be done many times:
%
As an example consider the (fictive) mTree nodes $[2,1]$ and $[1,2]$ at position $k=3$. 
%
To compute the successors of node $[2,1]$ we call Algorithm~\ref{alg:imcdf} with arguments $(4,[2,1])$, $(4,[3,1])$ and $(4,[2,2])$. 
%
We store the results of these calculation in a map that we call MCDF cache with the algorithm arguments ($k$ and the minimum protected candidates of each group) as key and the corresponding mcdf as value.
%
Next we compute the successors of node $[1,2]$ and call Algorithm~\ref{alg:imcdf} with arguments $(4,[1,2])$, $(4,[2,2])$ and $(4,[1,3])$. 
%
We see that we would compute the mcdf for $(4,[2,2])$ twice, but instead we can now read it from the MCDF cache.

Furthermore, if our example has symmetric minimum proportions $p_1 = p_1$, the mcdf of $(4,[2,1])$ is equal to $(4,[1,2])$ and $\textit{mcdf}(4,[1,3]) = \textit{mcdf}(4,[3,1])$. 
%
Generally, if $p_1 = p_2 = \cdots = p_{|G|}$, we can make use of the mTree's symmetry: we calculate the mcdf only for node $m(i)$ and store it in the cache \emph{as well as its mirror} (see Section~\ref{subsubsec:discarding-symmetric-nodes}), because their mcdf values are the same.

Note that the mcdf computation is only depends on $p_G$ and not on $alpha$. 
%
We can therefore persists the MCDF cache on disk for a particular vector $p_G$ and load it for any mTree calculation with the same $p_G$ in the future.
%
This also saves additional computation time during significance adjustment.

\subsubsection{Discarding symmetric nodes}
\label{subsubsec:discarding-symmetric-nodes}
In case of equal minimum proportions for all groups $p_1 = p_2 = \ldots = p_|G|$ the mTree shows a convenient property that we can use to reduce additional space and computation time. 
%
Remember that whenever the mcdf value falls below $\alpha$ for a particular position $i$, we have to put a protected candidate onto $i$. 
%
For equal minimum proportions the tree branches into $|G| - 1$ symmetric nodes $m(i)$ of the same likelyhood.
%
As an example reconsider the mTree from Figure~\ref{fig:mtree-symmetric-adjusted} at level 6. 
%
For two protected groups with minimum proportions $[1/3, 1/3]$ we see that the tree branches into two symmetric nodes $[1, 0]$ and $[0,1]$. 
%
Both have the same mcdf values.
%
We store only one of the nodes and flag it as ``has mirrored node'' and continue our mTree computation only in the stored branch.
%
This way we save half of the space and computation time needed, without loosing any information about the tree. 

\subsubsection{Stored mTrees}
\label{subsubsec:stored-mtrees}
During the computation of an adjusted mTree with parameters $k,p_G , \alpha$ we calculate many temporary mTrees (first the unadjusted ones, then the ones for the regression algorithm, then the ones for the binary search steps).
%
We persist all of the temporary mTrees plus the final tree in files for later usage.
%
The filenames contain the tree parameters and whether or not it is adjusted and its probability to fail a fair ranking $\failprob$.
%
If any of these trees is needed at a later point in time it can be loaded from disc instead of being recomputed, be it as input for multinomial \algoFAIR or as temporary tree during a new adjusted mTree computation.




