%!TEX root = main.tex

\section{The Fair Top-k Ranking Problem}\label{sec:problem}

In this section, we first present the needed notation (\S\ref{subsec:preliminaries}), then the ranked group fairness criterion (\S\ref{subsec:group-fairness}) and criteria for utility (\S\ref{subsec:individual-fairness}). Finally we provide a formal problem statement (\S\ref{subsec:problem-statement}).
%
This formalization extends the one previously presented for a binomial setting (one protected group)~\cite{zehlike2017fair} into a multinomial setting.

\subsection{Preliminaries and Notation}
\label{subsec:preliminaries}
\textcolor[rgb]{0.00,0.00,1.00}{We consider a set of candidates} $[n] = \{ 1, 2, \dots, n \}$  out of which $k$ candidates will be selected. \textcolor[rgb]{0.00,0.00,1.00}{We are also given} $q_c$ for \textcolor[rgb]{0.00,0.00,1.00}{each} $c \in [n]$, denoting the ``utility'' of candidate $c$: this can be interpreted as an overall summary of the fitness of candidate $c$ for the specific job, task, or search query, and it could be obtained by the combination of several different attributes.
If this utility is computed by a machine learning model, an effort must be done to prevent preexisting and technical biases with respect to a protected group to be embodied in the model (see, e.g., \cite{Sweeney2013}).
%
We define a set of candidate groups $G = \left\{g_0, g_1, \ldots\textcolor[rgb]{0.00,0.00,1.00}{ g_{|G|}}\right\}$ that form a partition of $[n]$. We will consider $g_0$ as non-protected (or privileged) and all remaining groups as protected (or disadvantaged).
%
To simplify the presentation of the algorithms, we will assume there are at least $k$ candidates in each group. % enough candidates of each group, i.e., at least $k$ of each kind.

Let ${\mathcal P}_{k,n}$ represent all the subsets of $[n]$ containing exactly $k$ elements.
%
Let ${\mathcal T}_{k,n}$ represent the union of all permutations of sets in ${\mathcal P}_{k,n}$, i.e., the solution space of the top-$k$ ranking problem.
%
For a permutation $\tau \in {\mathcal T}_{k,n}$ and an element $c \in [n]$, let
\[
r(c, \tau) = \begin{cases}
\mathrm{rank~of~} c \mathrm{~in~} \tau & \mathrm{if~} c \in \tau~, \\
%|\tau| + 1 & \mathrm{otherwise}.
k + 1 & \mathrm{otherwise}.
\end{cases}
\]

We further define $\tau_g$ to be the number of elements of group $ g $ that are present in $\tau$, i.e. $\tau_g = | \{ c \in \tau \wedge c \in g \} |$.
%
We set $ \tau_G = \langle\tau_g\rangle_{g \in G}$, i.e., the vector that contains these numbers for each group.
%

\textcolor[rgb]{0.00,0.00,1.00}{Let $cb \in {\mathcal T}_{n,n}$ be the total ranking of all candidates by
 decreasing utility: $\forall u,v \in [n], u=cb(i), v = cb(j), i < j \implies q_u \ge q_v$.}
%
For simplicity of exposition, we will assume all utilities $q_c$ are different, although our algorithms do not require this to be the case.
%
We call this the \emph{color-blind} ranking of elements in $[n]$, because it simply focuses on the utility and ignores whether elements are protected or non-protected.
%
Let $\textit{cb}|_k = \langle \textit{cb}(1), \textit{cb}(2), \ldots, \textit{cb}(k) \rangle$ be a prefix of size $k$ of this ranking. \label{concept:color-blind-ranking} 
%

\begin{table}[t]
\caption{Notation.}
\CaptionMargin
\label{tbl:notation}
\small
\begin{tabular}{R{.2\linewidth}L{.75\linewidth}}\toprule
\multicolumn{2}{c}{Candidates} \\
\midrule
$[n]$ & Set of candidates \\
$q_c$ & Qualifications of candidate $c$ \\
$g_c \in G$ & 0 if candidate $c$ is in the non-protected group, $ >0 $ otherwise\\
$|G|$ & The number of protected groups \\
\midrule
\multicolumn{2}{c}{Rankings} \\
\midrule
${\mathcal T}_{k,n}$ & All permutations of $k$ elements of $[n]$ \\
$\tau$ & One such permutation \\
$r(c,\tau)$ & The position of candidate $c$ in $\tau$, or $|\tau|+1$ if $c \notin \tau$ \\
$ \tau_G~=~\left(\tau_1, \tau_2, \ldots, \tau_{|G|}\right)$ & Vector of number of elements from group $ g $ in $\tau$ \\
$\textit{cb}$ & The ``color-blind'' ranking of $[n]$ by decreasing $q_c$ \\
\midrule
\multicolumn{2}{c}{Group fairness criteria} \\
\midrule
$p_G~=~\left(p_1, p_2, \ldots, p_{|G|}\right)$ & Vector of minimum proportions for candidates of each protected group $ g > 0 $ \\
$\alpha$ & Significance value for ranked group fairness test \\
$\alphaadj$ & Adjusted significance for each fair representation test \\
\midrule
\multicolumn{2}{c}{Individual fairness criteria} \\
\midrule
$	\texttt{utility}(c,\tau)$ & Qualification difference between candidate $c$ and the least qualified candidate ranked above $c$ while $q_c > q_d$ \\
\midrule
\multicolumn{2}{c}{Model Adjustment} \\
\midrule
$ \failprob $ & Probability that our test fails on a fair ranking \\
$ m_{\alpha, p}(k)$ & Minimum number of protected candidates in top $k$ positions; a vector of integers in case of $|G| > 1$ \\
\bottomrule
\end{tabular}
\tablemargin
\end{table}

\spara{Fair top-$k$ ranking criteria.}\label{concept:criteria}
We would like to obtain $\tau \in {\mathcal T}_{k,n}$ with the following objectives, which we describe formally next: %\S\ref{subsec:group-fairness} and \S\ref{subsec:individual-fairness}:

\begin{enumerate}[{Criterion} 1.]
	\item Ranked group fairness: $\tau$ should fairly represent each protected group; \label{cond:ranking}

	\item Expected selection utility: $\tau$ should contain the most qualified candidates; and \label{cond:selection}

	\item Expected ordering utility: $\tau$ should be ordered by decreasing qualifications.\label{cond:ordering}
\end{enumerate}

We will provide a formal problem statement in \S\ref{subsec:problem-statement}, but first, we need to provide a formal definition of each of the criteria, which we do in the next sections.
\textcolor[rgb]{0.00,0.00,1.00}{The notation used in this paper is summarized on Table~\ref{tbl:notation}.}


\subsection{Group Fairness for Rankings}
\label{subsec:group-fairness}

We operationalize Criterion~\ref{cond:ranking} of Section~\ref{concept:criteria} by means of a \emph{ranked group fairness criterion}, which takes as input
\begin{inparaenum}[(i)]
	\item $ \tau_G $, the vector containing the number of candidates from each protected group in ranking $ \tau $, and
	\item $ p_G $, a vector containing minimum target proportions for each protected group.
\end{inparaenum}
Intuitively, this criterion declares the ranking as unfair if candidates in a protected group is far below the required number according to the target proportions.
%
Additionally, this criterion looks at the ordering in which those candidates appear.
%
Specifically, the ranked group fairness criterion compares the number of protected elements from each group \emph{in every prefix} of the ranking, with the expected number of protected elements if they were picked at random using a stochastic process with a multinomial distribution, such as the roll of a dice.

\begin{definition}[Multinomial Cumulative Distribution Function]
	\label{def:multinomialCDF}
	% We do not need to cite this -- ChaTo
  %	Adopting the notation from~\cite{multinomcdf}
	Let $ n \in \mathbb{N}$ be a number of trials where each trial results in one of the events $ E_1, E_2, \ldots, E_{|G|} $ and on each trial $ E_j $ occurs with probability $ p_j $.
	%
	Let then $X$ %=\left\{X_1, X_2, \ldots, X_k\right\} $
	be a set of random variables that is multinomially distributed $ X \sim \operatorname{Mult}(n, p)$ with parameters $ n $ and $ p = \langle p_1, p_2, \ldots, p_{|G|} \rangle$, and let $ X_j $ be the number of trials in which event $ E_j $ occurs.
	%
	We then define $ F\left(X; n, p\right) = P\left(E_1 \leq X_1, E_2 \leq X_2, \ldots, E_{|G|} \leq X_{|G|}\right)$ the multinomial cumulative distribution function which computes the probability that each event $ E_j $ occurs at most $ X_j $ times in $ n $ trials given probabilities $ p $.
\end{definition}
With the multinomial CDF the ranked group fairness criterion is formulated as a statistical significance test, and we include a significance parameter ($\alpha \textcolor[rgb]{0.00,0.00,1.00}{\in [0,1]}$) corresponding to the probability of rejecting a fair ranking (i.e., a Type I error).

\begin{definition}[Fair representation condition]
	\label{def:fair-representation-condition}
	% Using n and p because they're standard notation for binomials
	Let $F(X;n,p)$ be the multinomial cumulative distribution function as defined above.
	%
	A set $\tau \subseteq \mathcal{T}_{k,n}$, having $\tau_G$ protected candidates from each group fairly represents all protected groups with minimal proportions $p_G = (p_1, p_2, \ldots, p_{|G|})$ and significance $\alpha$,
	%
	if $F(\tau_G;k,p_G) > \alpha$.
\end{definition}

This is equivalent to using a statistical test where the null hypothesis $H_0$ is that the protected elements of each group are represented with a sufficient proportion $p_t$ ($\forall g \in G, p_t \ge p_g$), and the alternative hypothesis $H_a$ is that the proportion of protected elements is insufficient ($\exists g \in G: p_t < p_g$). In this test, the p-value is $F(\tau_G; k, p_G)$ and we reject the null hypothesis, and thus declare the ranking as unfair, if the p-value is less than or equal to the threshold $\alpha$.
%
Note that according to this definition, in the case of a set of size one, either the element is in the protected group, and then we satisfy fair representation, or the element is not in the protected group, and then we satisfy fair representation if $1 - F > \alpha$.

The ranked group fairness criterion enforces the fair representation condition over all prefixes of the ranking:

\begin{definition}[Ranked group fairness condition]
	\label{def:ranked-group-fairness-condition}
	A ranking $\tau \in {\mathcal T}_{k,n}$ satisfies the ranked group fairness condition with parameters $p_G$ and $\alpha$, if for every prefix $\tau|_i = \langle \tau(1), \tau(2), \dots, \tau(i) \rangle$ with $1 \le i \le k$, the set $\tau|_i$ satisfies the fair representation condition with group target proportions $p$ and significance $\alphaadj = \adj(\alpha, k, p_G)$.
	%
	Function $\adj(\alpha, k, p_G)$ is a corrected significance to account for multiple hypotheses testing (described in Section~\ref{sec:model-adjustment}).
\end{definition}

We note \textcolor[rgb]{0.00,0.00,1.00}{there exists} a solution space of rankings that satisfy this condition for a given 3-tuple $(k, p_G, \alpha)$, instead of just a single ranking as it is the case when only one protected group is present.
We further note that a larger $\alpha$ means a larger probability of declaring a fair ranking as unfair.
%
In our experiments (Section~\ref{sec:experiments}), we use a relatively conservative setting of $\alpha=0.1$.
%
The ranked group fairness condition can be used to create a \emph{ranked group fairness measure}. For a ranking $\tau$ and probabilities $p_G$, the ranked group fairness measure is the maximum $\alpha \in [0,1]$ for which $\tau$ satisfies the ranked group fairness condition.
%
Larger values indicate a stricter adherence to the required number of protected elements at each position.

\subsection{Utility}
\label{subsec:individual-fairness}
Our notion of utility reflects the desire to select candidates that are potentially better qualified, and to rank them as high as possible.
%
In contrast with previous works~\cite{yang2016measuring,celis2017ranking}, we do not assume to know the utility contribution of a given candidate at a particular position, but instead we base our utility calculation on losses due to non-monotonicity (i.e., due to candidates not being ordered by decreasing scores anymore to satisfy the ranked group fairness constraint).
%
This can also be understood as a measure of individual unfairness, as it calculates the largest score difference between a high-scoring candidate ranked below a low-scoring candidate.

The qualifications may have been even proven to be biased against protected groups, as is the case with the COMPAS scores~\cite{angwin_2016_machine} that we use in the experiments of Section~\ref{sec:experiments}, but our approach can bound the effect of that bias, because the utility maximization is subject to the multinomial ranked group fairness constraint.
%
However, we denote again that due to different manifestations of bias we believe that measures of qualification are not comparable across groups of candidates.
%
This means that for the entire fair solution space we can guarantee maximized utility only within groups but not across and we want to stress again that maximizing utility over the entire set of candidates comes with a change in one's believe system in which candidate utilities are indeed comparable.
%
In such a case we would question the usage of a post-processing algorithm in the first place.
%
However we want to operationalize the selection and ordering utility criterion from Section~\ref{subsec:preliminaries} and provide means for the user of our algorithm to estimate the loss of ranking relevance w.r.t. the colorblind ranking and hence define the following utility measures.

\note[Meike]{The whole paragraph above is unclear. It should be rephrased. 
	Relate to old paper and say that optimality proof is no longer possible. Give black and white females example. } 

\spara{Ranked utility.}
The ranked individual utility associated to a candidate $c$ in a ranking $\tau$, compares it against the least qualified candidate ranked above it.

\begin{definition}[Ranked utility of an element]
	\label{def:rankedIndividualFairness}
	The ranked utility of an element $c \in [n]$ in ranking $\tau$, is:
	\[
	\texttt{utility}(c,\tau) = \begin{cases}
	\overline{q} - q_c &\textcolor[rgb]{0.00,0.00,1.00}{ \textrm{if~} \overline{q} < q_c \textrm{where~} \overline{q}\triangleq \min_{d: r(d,\tau) < r(c,\tau)} q_d } \\
	0 & \textrm{otherwise}\\
	\end{cases}
	\]
\end{definition}
%
\noindent By this definition, the maximum ranked individual utility that can be attained by an element is zero. %\note{It's weird to have something called utility which has its maximum in zero. It would have been more appropriate to call it something like \emph{individual unfairness}, but I guess it's too late to change terminology (same applies to several other notions).}
%
%Next, we apply the definition of ranked individual utility to two separate cases: when an element $i$ is included in the ranking, and when it is not included.

\spara{Selection utility.}
%
We operationalize Criterion~\ref{cond:selection} by means of a \emph{selection utility} objective, which we will use to prefer rankings in which the more qualified candidates are included, and the less qualified, excluded.
%
\begin{definition}[Selection utility]
	\label{def:selectionFairness}
	The selection utility of a ranking
	$\tau \in {\mathcal T}_{k,n}$ is \[\min_{c \in [n], c \notin \tau} \texttt{utility}(c,\tau)\].
\end{definition}
%
\noindent Naturally, a ``color-blind'' top-k ranking $\textit{cb}|_k$ maximizes selection utility, i.e., has selection utility zero.

\spara{Ordering utility and in-group monotonicity.}
%
We operationalize Criterion~\ref{cond:ordering} of Section \ref{concept:criteria} by means of an \emph{ordering utility} objective and an \emph{in-group monotonicity constraint}, which we will use to prefer top-$k$ lists in which the more qualified candidates are ranked above the less qualified ones.

\begin{definition}[Ordering utility]
	\label{def:orderingFairness}
	The ordering utility of a ranking $\tau \in {\mathcal T}_{k,n}$ is \[\min_{c \in \tau} \texttt{utility}(c,\tau)\].
\end{definition}

\noindent The ordering utility of a ranking is only concerned with the candidate attaining the worst (minimum) ranked individual utility. Instead, the in-group monotonicity constraints refer to all elements, and specifies that within groups candidates must be sorted by decreasing qualifications.

\begin{definition}[In-group monotonicity]
	\label{def:inGroupMonotonicity}
	A ranking $\tau \in {\mathcal T}_{k,n}$ satisfies the in-group monotonicity condition if $\forall c,d$ s.t. $g_c = g_d$, $r(c,\tau) < r(d,\tau) \Rightarrow q_c \ge q_d$.
\end{definition}

\noindent Again, the ``color-blind'' top-k ranking $\textit{cb}|_k$ maximizes ordering utility, i.e., has ordering utility zero; it also satisfies the in-group monotonicity constraint.

\spara{Connection to the individual fairness notion.}\label{concept:our-utility-individual-fairness}
%
Our notion of utility is centered on individuals, for instance by taking the minima instead of averaging.
%
While other choices are possible, this has the advantage that we can trace loss of utility to specific individuals. These are the people who are ranked below a less qualified candidate, or excluded from the ranking, due to the ranked group fairness constraint.
%
This is connected to the notion of individual fairness, which requires people to be treated consistently~\cite{Dwork2012}. Under this interpretation, a consistent treatment should require that two people with the same qualifications be treated equally, and any deviation from this is in our framework a utility loss. This allows trade-offs to be made explicit.

\subsection{Formal Problem Statement}
\label{subsec:problem-statement}
The criteria we have described allow for different problem statements, depending on whether we use ranked group fairness as a constraint and maximize ranked utility, or vice versa.
%In this paper, we study in depth the following problem statement (an algorithm is presented in Section~\ref{sec:algorithms}).

\newtheorem*{problem*}{Problem}
\begin{problem*}[Fair top-k ranking]
	Given a set of candidates $[n]$, \textcolor[rgb]{0.00,0.00,1.00}{a partition of $[n]$ in groups $G = \left\{g_0, g_1, \ldots, g_{|G|}\right\}$, the vector $p_G$ of minimum proportions per group,  and parameters $k \in \mathbb{N}^+$ and $\alpha \in [0,1]$}, produce a ranking $\tau \in {\mathcal T}_{k,n}$ that:
	\begin{compactenum}[(i)]
		\item \label{problem:constraint-monotonicity} satisfies the in-group monotonicity constraint;
		\item \label{problem:constraint-rank} satisfies ranked group fairness with parameters $p_G$ and $\alpha$;
		\item \label{problem:optimal-sel} achieves high selection utility subject to (\ref{problem:constraint-monotonicity}) and (\ref{problem:constraint-rank}); and
		\item \label{problem:maximum-ord} achieves high ordering utility subject to (\ref{problem:constraint-monotonicity}), (\ref{problem:constraint-rank}), and (\ref{problem:optimal-sel}).
	\end{compactenum}
\end{problem*}

\spara{Related problems.}\label{concept:related-problems}
%
Alternative problem definitions are possible with the general criteria described in Section~\ref{concept:criteria}.
%
For instance, instead of maintaining high selection and ordering utility, we may seek to always find the one ranking $\tau^*$ from all possible rankings that satisfy ranked group fairness that maximizes selection and ordering utility.
%
We acknowledge that this seems to be a tempting ``optimization'' of \algoFAIR but we believe that such a strategy is not fully compliant with multinomial ranked group fairness anymore.
%
As ranked group fairness is defined through a statistical process that corresponds to the roll of a dice, all possible ``fair'' solutions must have a chance $>0$ to be picked as the final result ranking.
%
As soon as $\tau^*$ becomes the only solution the algorithm finds, we will render true ranked group fairness obsolete.
%
Consider as a real world example again the case of different biases across groups in an intersectional setting:
%
Assuming we have a dataset with white, upper-class and black, lower-class people in which the utility criterion is lightly correlation with gender and strongly correlating with income class.
%
The protected group would be white women, black men and black women.
%
If we were to always choose the ranking that satisfies ranked group fairness and maximizes utility, we would \emph{always} reorder the result in favor of white women, while black men and particularly black women would fall behind.
%
Instead \algoFAIR should truly implement ranked group fairness in which all solutions (also those that favor blacks) have a certain chance to be accepted.
