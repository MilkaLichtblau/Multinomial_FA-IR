{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairsearchcore as fsc\n",
    "from fairsearchcore.models import FairScoreDoc\n",
    "from fairsearchcore.re_ranker import fair_top_k\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import *\n",
    "import scipy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LSAT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 300\n",
    "#p = 0.353 + 0.084 + 0.076 #sum of all protected proportions (sum(pstat))\n",
    "#p = 0.25 + 0.25 + 0.25 # sum of all protected proportions (sum(peq))\n",
    "p = 0.5 #sum of all protected proportions (p=0.5)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorblind_candidates = pd.read_csv('./data/LSAT/LSAT_sexRace_java.csv')\n",
    "colorblind_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>German Credit Sex+Age</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "#p = 0.217 + 0.063 + 0.044 + 0.032 + 0.061 #sum of all protected proportions (sum(pstat))\n",
    "#p = 5.0/6.0 # sum of all protected proportions (sum(peq))\n",
    "p = 0.5 #sum of all protected proportions (p=0.5)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorblind_candidates = pd.read_csv('./data/GermanCredit/germanCredit_sexAge_java.csv')\n",
    "colorblind_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compas 3 worst off</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 300\n",
    "#p = 0.028 + 0.012 + 0.134 #sum of all protected proportions (sum(pstat))\n",
    "#p = 0.25 + 0.25 + 0.25 # sum of all protected proportions (sum(peq))\n",
    "p = 0.5 #sum of all protected proportions (p=0.5)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorblind_candidates = pd.read_csv('./data/COMPAS/compas_worstThreeGroups_java.csv')\n",
    "#colorblind_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compas age</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "#p = 0.572 + 0.218 #sum of all protected proportions (sum(pstat))\n",
    "#p = 2.0/3.0 # sum of all protected proportions (sum(peq))\n",
    "p = 0.5 #sum of all protected proportions (p=0.5)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorblind_candidates = pd.read_csv('./data/COMPAS/compas_age_java.csv')\n",
    "colorblind_candidates[\"group\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Run Experiments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair = fsc.Fair(k, p, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtable = fair.create_adjusted_mtable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "protected_candidates = []\n",
    "unprotected_candidates = []\n",
    "for i in range(0,len(colorblind_candidates.index)):\n",
    "    score = colorblind_candidates.iloc[i][0]\n",
    "    if colorblind_candidates.iloc[i][1] >0:\n",
    "        protected = True\n",
    "    else:\n",
    "        protected = False\n",
    "    cid = colorblind_candidates.iloc[i][2]\n",
    "    if protected:\n",
    "        protected_candidates.append(FairScoreDoc(cid, score, protected))\n",
    "    else:\n",
    "        unprotected_candidates.append(FairScoreDoc(cid, score, protected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(id,score,protected)\n",
    "fair_ranking = fair_top_k(k,protected_candidates, unprotected_candidates, mtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_candidates = pd.DataFrame(columns=[\"score\",\"group\",\"uuid\"])\n",
    "ranked_list = []\n",
    "for cand in fair_ranking:\n",
    "    group = colorblind_candidates[(colorblind_candidates[\"uuid\"] == cand.id)].iloc[0][1]\n",
    "    fair_candidates = fair_candidates.append({'score': cand.score , 'group':group, 'uuid':cand.id }, ignore_index=True)\n",
    "    ranked_list.append(cand.id)\n",
    "\n",
    "remaining_ranking = pd.DataFrame(columns=[\"score\",\"group\",\"uuid\"])\n",
    "for i in range(0,len(colorblind_candidates.index)):\n",
    "    if colorblind_candidates[\"uuid\"][i] not in ranked_list:\n",
    "        remaining_ranking = remaining_ranking.append({'score': colorblind_candidates.iloc[i][0] , 'group':colorblind_candidates.iloc[i][1], 'uuid':colorblind_candidates.iloc[i][2] }, ignore_index=True)\n",
    "\n",
    "#remaining_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_ranking = fair_candidates\n",
    "colorblind_ranking = colorblind_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectionUtilityLossPerGroup(remainingRanking, fairRanking, result):\n",
    "    # add column to result frame\n",
    "    result[\"selectUtilLoss\"] = 0.0\n",
    "    # do evaluation for each group separately\n",
    "    for groupName in result[\"group\"]:\n",
    "        allExcludedCandidatesInGroup = remainingRanking.loc[remainingRanking[\"group\"] == groupName]\n",
    "        allIncludedCandidatesFromOtherGroups = fairRanking.loc[fairRanking[\"group\"] != groupName]\n",
    "        firstExcludedInGroup = allExcludedCandidatesInGroup.score.max()\n",
    "        worstAbove = allIncludedCandidatesFromOtherGroups.score.min()\n",
    "        selectUtilLoss = max(0, firstExcludedInGroup - worstAbove)\n",
    "        result.at[result[result[\"group\"] == groupName].index[0], \"selectUtilLoss\"] = selectUtilLoss\n",
    "    return result\n",
    "\n",
    "def orderingUtilityLossPerGroup(colorblindRanking, fairRanking, result):\n",
    "    result[\"orderUtilLoss\"] = 0.0\n",
    "    result[\"maxRankDrop\"] = 0\n",
    "    for groupName in result[\"group\"]:\n",
    "        allCandidatesInGroup = fairRanking.loc[fairRanking[\"group\"] == groupName]\n",
    "        allOthers = fairRanking.loc[fairRanking[\"group\"] != groupName]\n",
    "        for position, candidate in allCandidatesInGroup.iterrows():\n",
    "            allOthersAbove = allOthers.loc[0:position - 1]\n",
    "            worstScoreAbove = allOthersAbove.score.min()\n",
    "\n",
    "            # calculate ordering utility loss, should be maximum of all\n",
    "            orderUtilLoss = max(0.0, candidate.score - worstScoreAbove)\n",
    "            currentMaxLossPerGroup = result.at[result[result[\"group\"] == groupName].index[0], \"orderUtilLoss\"]\n",
    "            if orderUtilLoss > currentMaxLossPerGroup:\n",
    "                result.at[result[result[\"group\"] == groupName].index[0], \"orderUtilLoss\"] = orderUtilLoss\n",
    "\n",
    "            # calculate max rank drop for groups\n",
    "            originalPosition = colorblindRanking.loc[colorblindRanking['uuid'] == candidate.uuid].index[0]\n",
    "            rankdrop = position - originalPosition\n",
    "            currentMaxRankDrop = result.at[result[result[\"group\"] == groupName].index[0], \"maxRankDrop\"]\n",
    "            if rankdrop > currentMaxRankDrop:\n",
    "                result.at[result[result[\"group\"] == groupName].index[0], \"maxRankDrop\"] = rankdrop\n",
    "    return result\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10, gains=\"linear\"):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank k\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "    gains : str\n",
    "        Whether gains should be \"exponential\" or \"linear\" (default).\n",
    "    Returns\n",
    "    -------\n",
    "    NDCG @k : float\n",
    "    \"\"\"\n",
    "    best = dcg_score(y_true[:k], gains)\n",
    "    actual = dcg_score(y_score[:k], gains)\n",
    "    return actual / best\n",
    "\n",
    "def averageGroupExposureGain(colorblindRanking, fairRanking, result):\n",
    "    result[\"expGain\"] = 0.0\n",
    "    for groupName in result[\"group\"]:\n",
    "        allCandidatesInGroup_fairRanking = fairRanking.loc[fairRanking[\"group\"] == groupName]\n",
    "        allCandidatesInGroup_colorblindRanking = colorblindRanking.loc[colorblindRanking[\"group\"] == groupName]\n",
    "        groupBias_fairRanking = positionBias(allCandidatesInGroup_fairRanking)\n",
    "        groupBias_colorblind = positionBias(allCandidatesInGroup_colorblindRanking)\n",
    "        if groupBias_colorblind == 0 and groupBias_fairRanking == 0:\n",
    "            print(\"group \" + str(groupName) + \" did not appear in the top-k in both rankings\")\n",
    "        elif groupBias_fairRanking == 0:\n",
    "            print(\"group \" + str(groupName) + \" did not appear in the top-k in fair ranking\")\n",
    "            # expGain = -math.inf\n",
    "        elif groupBias_colorblind == 0:\n",
    "            print(\"group \" + str(groupName) + \" did not appear in the top-k in colorblind ranking\")\n",
    "            # expGain = math.inf\n",
    "        expGain = groupBias_fairRanking - groupBias_colorblind\n",
    "        result.at[result[result[\"group\"] == groupName].index[0], \"expGain\"] = expGain\n",
    "    return result\n",
    "\n",
    "def dcg_score(y_score, gains=\"exponential\"):\n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank k\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "    gains : str\n",
    "        Whether gains should be \"exponential\" (default) or \"linear\".\n",
    "    Returns\n",
    "    -------\n",
    "    DCG @k : float\n",
    "    \"\"\"\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_score - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_score\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "\n",
    "    # highest rank is 1 so +2 instead of +1\n",
    "    discounts = np.log2(np.arange(len(y_score)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def positionBias(ranking):\n",
    "    if ranking.empty:\n",
    "        # this case can happen if a group does not appear in the top-k at all\n",
    "        # we assign zero then\n",
    "        return 0\n",
    "    totalPositionBias = 0.0\n",
    "    for position, _ in ranking.iterrows():\n",
    "        if math.log2(position + 2) == 0.0:\n",
    "            print(position)\n",
    "        totalPositionBias = totalPositionBias + (1 / (math.log2(position + 2)))\n",
    "\n",
    "    return totalPositionBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_result = pd.DataFrame()\n",
    "fair_result[\"group\"] = fair_ranking['group'].unique()\n",
    "kay = len(fair_ranking)\n",
    "\n",
    "# individual fairness metrics\n",
    "fair_result = selectionUtilityLossPerGroup(remaining_ranking, fair_ranking, fair_result)\n",
    "fair_result = orderingUtilityLossPerGroup(colorblind_ranking, fair_ranking, fair_result)\n",
    "\n",
    "# performance metrics\n",
    "fair_result[\"ndcgLoss\"] = 1 - ndcg_score(colorblind_ranking[\"score\"].to_numpy(),\n",
    "                                                       fair_ranking[\"score\"].to_numpy(),\n",
    "                                                       k=kay)\n",
    "fair_result[\"kendallTau\"] = scipy.stats.kendalltau(colorblind_ranking.head(kay)[\"score\"].to_numpy(),\n",
    "                                                                         fair_ranking[\"score\"].to_numpy())[0]\n",
    "\n",
    "# group fairness metrics\n",
    "fair_result = averageGroupExposureGain(colorblind_ranking.head(kay), fair_ranking, fair_result)\n",
    "#fair_result = multi_fair_result.sort_values(by=['group'])\n",
    "#fair_result.to_csv(evalDir + experiment + \"/\" + kString + \"_\" + pString + \"_multiFairResult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_result \n",
    "fair_result.to_csv(\"CompasAge_oldFAIR_algo_sum_of_p05_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>selectUtilLoss</th>\n",
       "      <th>orderUtilLoss</th>\n",
       "      <th>maxRankDrop</th>\n",
       "      <th>ndcgLoss</th>\n",
       "      <th>kendallTau</th>\n",
       "      <th>expGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.828633e-09</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>1.277094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.122689e-07</td>\n",
       "      <td>1.890361e-07</td>\n",
       "      <td>23</td>\n",
       "      <td>1.828633e-09</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>-1.277094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group  selectUtilLoss  orderUtilLoss  maxRankDrop      ndcgLoss  kendallTau  \\\n",
       "0     1    0.000000e+00   0.000000e+00            0  1.828633e-09      0.9621   \n",
       "1     0    2.122689e-07   1.890361e-07           23  1.828633e-09      0.9621   \n",
       "\n",
       "    expGain  \n",
       "0  1.277094  \n",
       "1 -1.277094  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_ranking[\"group\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorblind_ranking[\"group\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
